import sys
import os
import re
import time
import traceback
import torch
import keyboard  # pip install keyboard
from PIL import ImageGrab

# --- 1. C·∫§U H√åNH FIX L·ªñI DLL TORCH ---
path_to_torch_dlls = r"C:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\lib"
if os.path.exists(path_to_torch_dlls):
    os.add_dll_directory(path_to_torch_dlls)

from PyQt5.QtWidgets import (QApplication, QMainWindow, QPushButton, QLabel, 
                             QVBoxLayout, QWidget, QFrame, QHBoxLayout)
from PyQt5.QtCore import Qt, QThread, pyqtSignal, QRect, QPoint
from PyQt5.QtGui import QCursor, QPainter, QColor, QPen, QBrush

# --- IMPORT MODELS ---
# pip install sentencepiece protobuf transformers
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModel

# --- BI·∫æN TO√ÄN C·ª§C ---
GLOBAL_OCR_MODEL = None
GLOBAL_OCR_TOKENIZER = None
GLOBAL_TRANS_MODEL = None
GLOBAL_TRANS_TOKENIZER = None

class GOTOCRWorker(QThread):
    result_ready = pyqtSignal(str)
    model_loaded_signal = pyqtSignal()

    def __init__(self, image_path=None, mode="scan"):
        super().__init__()
        self.image_path = image_path
        self.mode = mode

    def clean_text(self, text):
        """H√†m l√†m s·∫°ch r√°c OCR ƒë·ªÉ d·ªãch chu·∫©n h∆°n"""
        # 1. N·ªëi d·∫•u nh√°y: "school ' s" -> "school's"
        text = re.sub(r"\s+(['‚Äô])\s*([a-zA-Z])", r"'\2", text)
        # 2. N·ªëi d·∫•u c√¢u: "Hello ." -> "Hello."
        text = re.sub(r"\s+([.,!?;:])", r"\1", text)
        # 3. M·∫πo n·ªëi t·ª´ b·ªã ƒë·ª©t (VD: "handsomes t" -> "handsomest")
        text = re.sub(r"([a-zA-Z]{3,})\s+([a-zA-Z])\b", r"\1\2", text)
        # 4. X√≥a xu·ªëng d√≤ng th·ª´a
        text = text.replace("\n", " ")
        # 5. X√≥a kho·∫£ng tr·∫Øng k√©p
        text = re.sub(r"\s+", " ", text).strip()
        return text

    def run(self):
        global GLOBAL_OCR_MODEL, GLOBAL_OCR_TOKENIZER, GLOBAL_TRANS_MODEL, GLOBAL_TRANS_TOKENIZER
        try:
            # --- 1. N·∫°p Model OCR ---
            if GLOBAL_OCR_MODEL is None:
                self.result_ready.emit("üöÄ ƒêang n·∫°p Model OCR (GOT-2.0)...")
                model_ocr_name = 'ucaslcl/GOT-OCR2_0'
                GLOBAL_OCR_TOKENIZER = AutoTokenizer.from_pretrained(model_ocr_name, trust_remote_code=True)
                GLOBAL_OCR_MODEL = AutoModel.from_pretrained(
                    model_ocr_name, trust_remote_code=True, low_cpu_mem_usage=True, 
                    device_map='cuda', use_safetensors=True, 
                    pad_token_id=GLOBAL_OCR_TOKENIZER.eos_token_id
                )
                GLOBAL_OCR_MODEL = GLOBAL_OCR_MODEL.eval().cuda()

            # --- 2. N·∫°p Model D·ªãch ---
            if GLOBAL_TRANS_MODEL is None:
                self.result_ready.emit("üöÄ ƒêang n·∫°p Model NLLB-200...")
                model_trans_name = "facebook/nllb-200-distilled-600M"
                GLOBAL_TRANS_TOKENIZER = AutoTokenizer.from_pretrained(model_trans_name)
                GLOBAL_TRANS_MODEL = AutoModelForSeq2SeqLM.from_pretrained(model_trans_name)
                device = "cuda" if torch.cuda.is_available() else "cpu"
                GLOBAL_TRANS_MODEL = GLOBAL_TRANS_MODEL.to(device)
                
                self.result_ready.emit(f"‚úÖ S·∫µn s√†ng! (GPU: {torch.cuda.is_available()}). B·∫•m Alt+X ƒë·ªÉ ch·ª•p.")
                self.model_loaded_signal.emit()

            if self.mode == "preload": return

            # --- 3. Th·ª±c hi·ªán OCR ---
            if not self.image_path: return
            self.result_ready.emit("‚è≥ ƒêang ƒë·ªçc ch·ªØ t·ª´ ·∫£nh...")
            
            abs_image_path = os.path.abspath(self.image_path)
            res = GLOBAL_OCR_MODEL.chat(GLOBAL_OCR_TOKENIZER, abs_image_path, ocr_type='ocr')
            raw_text = str(res)
            
            # --- 4. L√†m s·∫°ch & D·ªãch (Chia c√¢u) ---
            self.result_ready.emit("‚è≥ ƒêang d·ªãch...")
            clean_text_str = self.clean_text(raw_text)
            
            # T√°ch c√¢u ƒë·ªÉ d·ªãch kh√¥ng b·ªã s√≥t
            sentences = re.split(r'([.!?]+)', clean_text_str)
            translated_parts = []
            
            # Gh√©p l·∫°i th√†nh c√°c c√¢u ho√†n ch·ªânh (Text + D·∫•u c√¢u)
            full_sentences = []
            current_sent = ""
            for part in sentences:
                if re.match(r'[.!?]+', part):
                    current_sent += part
                    full_sentences.append(current_sent)
                    current_sent = ""
                else:
                    current_sent += part
            if current_sent: full_sentences.append(current_sent)

            # D·ªãch t·ª´ng c√¢u
            device = GLOBAL_TRANS_MODEL.device
            tgt_lang = "vie_Latn"
            
            for sent in full_sentences:
                if len(sent.strip()) < 2: continue
                
                inputs = GLOBAL_TRANS_TOKENIZER(sent, return_tensors="pt").to(device)
                translated_tokens = GLOBAL_TRANS_MODEL.generate(
                    **inputs, 
                    forced_bos_token_id=GLOBAL_TRANS_TOKENIZER.lang_code_to_id[tgt_lang], 
                    max_length=512
                )
                trans_text = GLOBAL_TRANS_TOKENIZER.batch_decode(translated_tokens, skip_special_tokens=True)[0]
                translated_parts.append(trans_text)

            final_vn = " ".join(translated_parts)
            final_output = f"üá¨üáß G·ªêC:\n{clean_text_str}\n\nüáªüá≥ D·ªäCH:\n{final_vn}"
            self.result_ready.emit(final_output)

        except Exception as e:
            traceback.print_exc()
            self.result_ready.emit(f"L·ªói: {str(e)}")

# --- PH·∫¶N SNIPPING TOOL (ƒê√É FIX L·ªñI V√ôNG CH·ªåN C≈®) ---
class SnippingWidget(QWidget):
    snippet_taken = pyqtSignal(object) 

    def __init__(self):
        super().__init__()
        self.setWindowFlags(Qt.WindowStaysOnTopHint | Qt.FramelessWindowHint | Qt.Tool)
        self.setAttribute(Qt.WA_TranslucentBackground)
        self.setCursor(Qt.CrossCursor)
        self.start_point = None
        self.end_point = None
        self.is_sniping = False

    def start_selection(self):
        # FIX: Reset t·ªça ƒë·ªô ƒë·ªÉ kh√¥ng hi·ªán l·∫°i khung ƒë·ªè c≈©
        self.start_point = None
        self.end_point = None
        self.setGeometry(QApplication.primaryScreen().geometry())
        self.show()
        self.activateWindow()

    def paintEvent(self, event):
        if not self.isVisible(): return
        painter = QPainter(self)
        painter.setRenderHint(QPainter.Antialiasing)
        painter.setBrush(QColor(0, 0, 0, 100))
        painter.setPen(Qt.NoPen)
        painter.drawRect(self.rect())

        if self.start_point and self.end_point:
            rect = QRect(self.start_point, self.end_point).normalized()
            painter.setCompositionMode(QPainter.CompositionMode_Clear)
            painter.drawRect(rect)
            painter.setCompositionMode(QPainter.CompositionMode_SourceOver)
            painter.setPen(QPen(Qt.red, 2))
            painter.setBrush(Qt.NoBrush)
            painter.drawRect(rect)

    def mousePressEvent(self, event):
        self.start_point = event.pos()
        self.end_point = event.pos()
        self.is_sniping = True
        self.update()

    def mouseMoveEvent(self, event):
        if self.is_sniping:
            self.end_point = event.pos()
            self.update()

    def mouseReleaseEvent(self, event):
        if not self.is_sniping: return
        self.is_sniping = False
        rect = QRect(self.start_point, event.pos()).normalized()
        self.hide() 
        if rect.width() > 10 and rect.height() > 10:
            x, y = rect.x(), rect.y()
            w, h = rect.width(), rect.height()
            try:
                img = ImageGrab.grab(bbox=(x, y, x+w, y+h))
                img.save("capture.jpg", quality=100)
                self.snippet_taken.emit("capture.jpg")
            except Exception as e:
                print(e)

# --- GIAO DI·ªÜN CH√çNH (ƒê√É FIX L·ªñI N√öT B·∫§M) ---
class ResultWindow(QMainWindow):
    request_snip_signal = pyqtSignal()

    def __init__(self):
        super().__init__()
        # C·∫•u h√¨nh c·ª≠a s·ªï kh√¥ng vi·ªÅn, lu√¥n n·ªïi
        self.setWindowFlags(Qt.FramelessWindowHint | Qt.WindowStaysOnTopHint)
        self.setAttribute(Qt.WA_TranslucentBackground)
        self.resize(500, 400)
        self.old_pos = None

        self.central_widget = QWidget()
        self.setCentralWidget(self.central_widget)
        self.layout = QVBoxLayout(self.central_widget)
        
        self.frame = QFrame()
        self.frame.setStyleSheet("""
            QFrame {
                background-color: rgba(20, 20, 20, 0.95);
                border: 2px solid #00ffcc;
                border-radius: 10px;
                color: white;
            }
        """)
        self.layout.addWidget(self.frame)
        self.frame_layout = QVBoxLayout(self.frame)

        # Ti√™u ƒë·ªÅ
        self.lbl_title = QLabel("NLLB-200 TRANSLATOR (Alt + X)")
        self.lbl_title.setStyleSheet("font-weight: bold; color: #00ffcc; font-size: 14px; border: none;")
        self.frame_layout.addWidget(self.lbl_title)

        # K·∫øt qu·∫£
        self.lbl_result = QLabel("ƒêang kh·ªüi ƒë·ªông Model...")
        self.lbl_result.setWordWrap(True)
        self.lbl_result.setAlignment(Qt.AlignTop | Qt.AlignLeft)
        self.lbl_result.setStyleSheet("border: none; padding: 5px; font-size: 13px;")
        self.lbl_result.setTextInteractionFlags(Qt.TextSelectableByMouse)
        self.frame_layout.addWidget(self.lbl_result)
        self.frame_layout.addStretch()

        # N√∫t Thu nh·ªè (FIX L·ªñI)
        self.btn_close = QPushButton("Thu nh·ªè (-)")
        self.btn_close.clicked.connect(self.handle_minimize) # D√πng h√†m ri√™ng
        self.btn_close.setStyleSheet("background: #444; color: white; border-radius: 5px; padding: 6px;")
        self.frame_layout.addWidget(self.btn_close)

        # Worker & Signals
        self.snipper = SnippingWidget()
        self.snipper.snippet_taken.connect(self.process_image)

        self.preload_worker = GOTOCRWorker(mode="preload")
        self.preload_worker.result_ready.connect(self.update_status)
        self.preload_worker.start()

        self.request_snip_signal.connect(self.start_snipping)
        keyboard.add_hotkey('alt+x', self.emit_snip_signal)

    def handle_minimize(self):
        # √âp c·ª≠a s·ªï thu nh·ªè
        self.setWindowState(Qt.WindowMinimized)

    def emit_snip_signal(self):
        self.request_snip_signal.emit()

    def start_snipping(self):
        self.hide()
        self.snipper.start_selection()

    def process_image(self, img_path):
        self.showNormal() # Hi·ªán l·∫°i c·ª≠a s·ªï
        self.activateWindow()
        self.update_status("‚è≥ ƒêang x·ª≠ l√Ω ·∫£nh...")
        self.worker = GOTOCRWorker(image_path=img_path, mode="scan")
        self.worker.result_ready.connect(self.update_status)
        self.worker.start()

    def update_status(self, text):
        self.lbl_result.setText(text)

    # --- FIX L·ªñI K√âO C·ª¨A S·ªî ---
    def mousePressEvent(self, event):
        if event.button() == Qt.LeftButton:
            # N·∫øu b·∫•m v√†o n√∫t th√¨ KH√îNG t√≠nh l√† k√©o c·ª≠a s·ªï
            if isinstance(self.childAt(event.pos()), QPushButton):
                return
            self.old_pos = event.globalPos()

    def mouseMoveEvent(self, event):
        if self.old_pos: 
            delta = event.globalPos() - self.old_pos
            self.move(self.pos() + delta)
            self.old_pos = event.globalPos()

    def mouseReleaseEvent(self, event):
        self.old_pos = None

if __name__ == "__main__":
    app = QApplication(sys.argv)
    window = ResultWindow()
    window.show()
    sys.exit(app.exec_())
